{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom IPython.display import display # used to display multiple command outputs in same cell\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-01T16:18:12.526920Z","iopub.execute_input":"2022-12-01T16:18:12.527437Z","iopub.status.idle":"2022-12-01T16:18:12.539746Z","shell.execute_reply.started":"2022-12-01T16:18:12.527370Z","shell.execute_reply":"2022-12-01T16:18:12.538140Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/home-data-for-ml-course/sample_submission.csv\n/kaggle/input/home-data-for-ml-course/sample_submission.csv.gz\n/kaggle/input/home-data-for-ml-course/train.csv.gz\n/kaggle/input/home-data-for-ml-course/data_description.txt\n/kaggle/input/home-data-for-ml-course/test.csv.gz\n/kaggle/input/home-data-for-ml-course/train.csv\n/kaggle/input/home-data-for-ml-course/test.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"##### *Loading test and train files*","metadata":{}},{"cell_type":"code","source":"# Editing the setting to show all the columns and rows\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:18:15.369654Z","iopub.execute_input":"2022-12-01T16:18:15.370138Z","iopub.status.idle":"2022-12-01T16:18:15.376570Z","shell.execute_reply.started":"2022-12-01T16:18:15.370100Z","shell.execute_reply":"2022-12-01T16:18:15.374926Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Storing train and test csv file path\ntrain_path = \"../input/home-data-for-ml-course/train.csv\"\ntest_path = \"../input/home-data-for-ml-course/test.csv\"\n\n# loading train and test csv files into a panda dataframe\ntrain_df = pd.read_csv(train_path)\ntest_df = pd.read_csv(test_path)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:18:17.644233Z","iopub.execute_input":"2022-12-01T16:18:17.644666Z","iopub.status.idle":"2022-12-01T16:18:17.728114Z","shell.execute_reply.started":"2022-12-01T16:18:17.644626Z","shell.execute_reply":"2022-12-01T16:18:17.726507Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Analyzing train and test data","metadata":{}},{"cell_type":"code","source":"# Finding number of rows and columns in train and test data\nprint(\"Training DataFrame\")\ndisplay(train_df.shape)\nprint(\"Testing DataFrame\")\ndisplay(test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T10:42:44.057578Z","iopub.execute_input":"2022-11-30T10:42:44.057966Z","iopub.status.idle":"2022-11-30T10:42:44.072806Z","shell.execute_reply.started":"2022-11-30T10:42:44.057935Z","shell.execute_reply":"2022-11-30T10:42:44.071320Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Top 5 rows in train and test df\nprint(\"Training DataFrame Snippet\")\ndisplay(train_df.head())\nprint(\"Testing DataFrame Snippet\")\ndisplay(test_df.head())","metadata":{"execution":{"iopub.status.busy":"2022-11-30T11:01:46.539241Z","iopub.execute_input":"2022-11-30T11:01:46.539644Z","iopub.status.idle":"2022-11-30T11:01:46.661656Z","shell.execute_reply.started":"2022-11-30T11:01:46.539610Z","shell.execute_reply":"2022-11-30T11:01:46.660465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_summary(df):\n#     Copying the dataframe passed into a different dataframe\n    x = df.copy()\n    \n#     Creating empty dataframe\n    summary_df = pd.DataFrame()\n    \n#     Storing Column names as values\n    summary_df[\"columns\"] = list(x.columns.values)\n    \n#     Adding data type of each column\n    summary_df[\"data_type\"] = \"\"\n    \n    for i in range(len(summary_df)):\n        summary_df.loc[i, [\"data_type\"]] = x[summary_df.loc[i,\"columns\"]].dtypes\n    \n#     Adding number of rows for each columns\n    summary_df[\"#_rows\"] = len(x)\n    \n#     Number of null values in each columns\n    summary_df[\"#_null_values\"] = \"\"\n    \n    for i in range(len(summary_df)):\n         summary_df.loc[i, [\"#_null_values\"]] = x[summary_df.loc[i,\"columns\"]].isnull().sum()\n    \n#     Number of unique values in each columns\n    summary_df[\"#_unique_values\"] = \"\"\n    \n    for i in range(len(summary_df)):\n         summary_df.loc[i, [\"#_unique_values\"]] = len(x[summary_df.loc[i,\"columns\"]].unique())\n    \n#     Returning the summary dataframe\n    return summary_df","metadata":{"execution":{"iopub.status.busy":"2022-11-30T12:07:52.886928Z","iopub.execute_input":"2022-11-30T12:07:52.887369Z","iopub.status.idle":"2022-11-30T12:07:52.897172Z","shell.execute_reply.started":"2022-11-30T12:07:52.887333Z","shell.execute_reply":"2022-11-30T12:07:52.895816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test and train summary\ntrain_summary_df = create_summary(train_df)\ntest_summary_df = create_summary(test_df)\n\nsummary_df = pd.merge(train_summary_df, test_summary_df, how = \"outer\", on = \"columns\",\n                    suffixes=['_train','_test'])\n\ndisplay(summary_df)","metadata":{"execution":{"iopub.status.busy":"2022-11-30T12:07:53.891499Z","iopub.execute_input":"2022-11-30T12:07:53.891912Z","iopub.status.idle":"2022-11-30T12:07:54.478083Z","shell.execute_reply.started":"2022-11-30T12:07:53.891881Z","shell.execute_reply":"2022-11-30T12:07:54.476992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Description of all numerical columns in train and test data\nprint(\"Training DataFrame Numerical Column Description\")\ndisplay(train_df.describe())\nprint(\"Testing DataFrame Numerical Column Description\")\ndisplay(test_df.describe())","metadata":{"execution":{"iopub.status.busy":"2022-11-30T12:10:04.572615Z","iopub.execute_input":"2022-11-30T12:10:04.572993Z","iopub.status.idle":"2022-11-30T12:10:04.812377Z","shell.execute_reply.started":"2022-11-30T12:10:04.572963Z","shell.execute_reply":"2022-11-30T12:10:04.811069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Code to specifically see what columns have null values and how many null values\n\n# train_df.loc[:,train_df.columns[train_df.isnull().any()]].isnull().sum()\n# test_df.loc[:,test_df.columns[test_df.isnull().any()]].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-11-30T12:10:14.099889Z","iopub.execute_input":"2022-11-30T12:10:14.100303Z","iopub.status.idle":"2022-11-30T12:10:14.105653Z","shell.execute_reply.started":"2022-11-30T12:10:14.100257Z","shell.execute_reply":"2022-11-30T12:10:14.104228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = train_df[\"MSSubClass\"].unique().tolist()\nx.sort()\nprint(x)\ny = test_df[\"MSSubClass\"].unique().tolist()\ny.sort()\nprint(y)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:30:20.640590Z","iopub.execute_input":"2022-12-01T16:30:20.641105Z","iopub.status.idle":"2022-12-01T16:30:20.649864Z","shell.execute_reply.started":"2022-12-01T16:30:20.641065Z","shell.execute_reply":"2022-12-01T16:30:20.648150Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"[20, 30, 40, 45, 50, 60, 70, 75, 80, 85, 90, 120, 160, 180, 190]\n[20, 30, 40, 45, 50, 60, 70, 75, 80, 85, 90, 120, 150, 160, 180, 190]\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df[\"MSSubClass\"].unique().tolist()","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:24:43.141198Z","iopub.execute_input":"2022-12-01T16:24:43.142559Z","iopub.status.idle":"2022-12-01T16:24:43.151991Z","shell.execute_reply.started":"2022-12-01T16:24:43.142514Z","shell.execute_reply":"2022-12-01T16:24:43.150520Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"[60, 20, 70, 50, 190, 45, 90, 120, 30, 85, 80, 160, 75, 180, 40]"},"metadata":{}}]},{"cell_type":"code","source":"test_df[\"MSSubClass\"].unique().tolist()","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:24:48.994134Z","iopub.execute_input":"2022-12-01T16:24:48.994603Z","iopub.status.idle":"2022-12-01T16:24:49.004457Z","shell.execute_reply.started":"2022-12-01T16:24:48.994559Z","shell.execute_reply":"2022-12-01T16:24:49.003033Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"[20, 60, 120, 160, 80, 30, 50, 90, 85, 190, 45, 70, 75, 180, 40, 150]"},"metadata":{}}]},{"cell_type":"code","source":"import collections\ncompare = lambda x, y: collections.Counter(x) == collections.Counter(y)\ncompare(train_df[\"MSSubClass\"].unique().tolist(), test_df[\"MSSubClass\"].unique().tolist())","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:30:52.211416Z","iopub.execute_input":"2022-12-01T16:30:52.211817Z","iopub.status.idle":"2022-12-01T16:30:52.221058Z","shell.execute_reply.started":"2022-12-01T16:30:52.211785Z","shell.execute_reply":"2022-12-01T16:30:52.219930Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}]},{"cell_type":"code","source":"def buggy_column(x, y, a, b):\n#     Storing arguements into a variable\n    identifier = x\n    predict = y\n    train_df = a\n    test_df = b\n    \n#     Finding column name in each data set\n    train_df_columns = train_df.columns.values.tolist()\n    test_df_columns = test_df.columns.values.tolist()\n    \n#     Checking if supplied identifier is in train and test dataframe\n    if identifier not in train_df_columns:\n        return print(\"Given identifer column is not present in train dataframe\")\n    if identifier not in test_df_columns:\n        return print(\"Given identifer column is not present in test dataframe\")\n\n#     Checking if predict column is present in the train_df\n    if predict not in train_df_columns:\n        return print(\"Given column to predict is not present in train dataframe\")\n    \n#     Checking if all the columns of train_df is present in test_df\n    not_present_columns = []\n    for i in train_df_columns:\n        if (i not in test_df_columns) or (i != predict):\n            not_present_columns.append(i)\n        print(\"Above train dataframe columns are missing from test dataframe\")\n        print(not_present_columns)\n    \n#     Checing if all the values in each column of train and test are present in each other\n    buggy_columns = []\n    for i in train_df_columns:\n        if i not in not_present_columns:\n            \n        \n\n    \n    return","metadata":{"execution":{"iopub.status.busy":"2022-12-01T13:57:23.907127Z","iopub.execute_input":"2022-12-01T13:57:23.907586Z","iopub.status.idle":"2022-12-01T13:57:23.917626Z","shell.execute_reply.started":"2022-12-01T13:57:23.907547Z","shell.execute_reply":"2022-12-01T13:57:23.916235Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Identify the columns in test and train data for whom values dont match\n\nbuggy_column(\"columns\", \"a\", train_df, test_df)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T13:57:44.573266Z","iopub.execute_input":"2022-12-01T13:57:44.574208Z","iopub.status.idle":"2022-12-01T13:57:44.581549Z","shell.execute_reply.started":"2022-12-01T13:57:44.574130Z","shell.execute_reply":"2022-12-01T13:57:44.580429Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Given identifer column is not present in train dataframe\nGiven identifer column is not present in train dataframe\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Value imputation","metadata":{}},{"cell_type":"code","source":"# MiscFeature can be dropped as we dont know the nature of data\n# Creating a copy of tran and test data and dropping MiscFeature column in both","metadata":{},"execution_count":null,"outputs":[]}]}